{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e9ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4241120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf284bc4",
   "metadata": {},
   "source": [
    "## Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766c59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    num_layers:int=12\n",
    "    num_heads:int=32\n",
    "    d_model:int=128\n",
    "    dropout:float=0.1\n",
    "    layer_norm_eps:float=1e-12\n",
    "    activation:str=\"gelu\"\n",
    "    vocab_size:int=40857\n",
    "    max_seq_len:int=256\n",
    "    learning_rate:float=1e-4\n",
    "    batch_size:float=64\n",
    "        \n",
    "config=Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3c03f",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5ba216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/test.tfrecords',\n",
       " '../data/processed/training.tfrecords',\n",
       " '../data/processed/vocab.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob.glob('../data/processed/*')\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b461d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-23 17:35:57.669842: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.TFRecordDataset(filenames[1])\n",
    "test_data = tf.data.TFRecordDataset(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c764c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_tf_records(element):\n",
    "    # Parse the input `tf.train.Example` proto using the dictionary schema.\n",
    "    schema = {\n",
    "        \"info\": tf.io.FixedLenFeature([1], tf.int64),  # [user]\n",
    "        \"x_masked_tokens\": tf.io.FixedLenFeature([256], tf.int64),\n",
    "        \"y_tokens\": tf.io.FixedLenFeature([256], tf.int64),\n",
    "        \"mask_layer\": tf.io.FixedLenFeature([256], tf.int64),\n",
    "    }\n",
    "    content = tf.io.parse_single_example(element, schema)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e02f0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_records = train_data.map(_parse_tf_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95ac86bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {info: (1,), mask_layer: (256,), x_masked_tokens: (256,), y_tokens: (256,)}, types: {info: tf.int64, mask_layer: tf.int64, x_masked_tokens: tf.int64, y_tokens: tf.int64}>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "089e5c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>x_masked_tokens</th>\n",
       "      <th>y_tokens</th>\n",
       "      <th>mask_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0]</td>\n",
       "      <td>[22, 6, 5, 25, 12, 40857, 26, 14, 34, 21, 1, 4...</td>\n",
       "      <td>[22, 6, 5, 25, 12, 3, 26, 14, 34, 21, 1, 4, 32...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[170, 171, 298, 282, 316, 330, 148, 301, 304, ...</td>\n",
       "      <td>[170, 171, 298, 282, 316, 330, 148, 301, 304, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[165, 40857, 512, 181, 185, 475, 471, 476, 473...</td>\n",
       "      <td>[165, 470, 512, 181, 185, 475, 471, 476, 473, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4]</td>\n",
       "      <td>[40, 40857, 533, 540, 527, 528, 40857, 151, 52...</td>\n",
       "      <td>[40, 0, 533, 540, 527, 528, 530, 151, 529, 517...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5]</td>\n",
       "      <td>[558, 162, 562, 43, 51, 44, 158, 557, 40857, 5...</td>\n",
       "      <td>[558, 162, 562, 43, 51, 44, 158, 557, 58, 561,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  info                                    x_masked_tokens  \\\n",
       "0  [0]  [22, 6, 5, 25, 12, 40857, 26, 14, 34, 21, 1, 4...   \n",
       "1  [2]  [170, 171, 298, 282, 316, 330, 148, 301, 304, ...   \n",
       "2  [3]  [165, 40857, 512, 181, 185, 475, 471, 476, 473...   \n",
       "3  [4]  [40, 40857, 533, 540, 527, 528, 40857, 151, 52...   \n",
       "4  [5]  [558, 162, 562, 43, 51, 44, 158, 557, 40857, 5...   \n",
       "\n",
       "                                            y_tokens  \\\n",
       "0  [22, 6, 5, 25, 12, 3, 26, 14, 34, 21, 1, 4, 32...   \n",
       "1  [170, 171, 298, 282, 316, 330, 148, 301, 304, ...   \n",
       "2  [165, 470, 512, 181, 185, 475, 471, 476, 473, ...   \n",
       "3  [40, 0, 533, 540, 527, 528, 530, 151, 529, 517...   \n",
       "4  [558, 162, 562, 43, 51, 44, 158, 557, 58, 561,...   \n",
       "\n",
       "                                          mask_layer  \n",
       "0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
       "3  [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(\n",
    "    train_tf_records.as_numpy_iterator(),\n",
    "    columns=['info', 'x_masked_tokens', 'y_tokens', 'mask_layer']\n",
    ")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea32765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f6bc374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.vstack(df_train.x_masked_tokens.to_numpy()), \n",
    "    np.vstack(df_train.y_tokens.to_numpy()), \n",
    "    np.vstack(df_train.mask_layer.to_numpy()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "426a6221",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ds = movies_ds.shuffle(1000).batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc2b856",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24114d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert4rec.bert import BertModel\n",
    "from bert4rec.trainer import BertTrainer\n",
    "# %autoreload 2\n",
    "# from bert4rec.trainer import BertTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1181ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " positional_embedding (Posit  multiple                 5262592   \n",
      " ionalEmbedding)                                                 \n",
      "                                                                 \n",
      " transformer_encoder_layer (  multiple                 198528    \n",
      " TransformerEncoderLayer)                                        \n",
      "                                                                 \n",
      " transformer_encoder_layer_1  multiple                 198528    \n",
      "  (TransformerEncoderLayer)                                      \n",
      "                                                                 \n",
      " transformer_encoder_layer_2  multiple                 198528    \n",
      "  (TransformerEncoderLayer)                                      \n",
      "                                                                 \n",
      " transformer_encoder_layer_3  multiple                 198528    \n",
      "  (TransformerEncoderLayer)                                      \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      "  (TransformerEncoderLayer)                                      \n",
      "                                                                 \n",
      " transformer_encoder_layer_5  multiple                 198528    \n",
      "  (TransformerEncoderLayer)                                      \n",
      "                                                                 \n",
      " transformer_encoder_layer_6  multiple                 198528    \n",
      "  (TransformerEncoderLayer)                                      \n",
      "                                                                 \n",
      " transformer_encoder_layer_7  multiple                 198528    \n",
      "  (TransformerEncoderLayer)                                      \n",
      "                                                                 \n",
      " transformer_encoder_layer_8  multiple                 198528    \n",
      "  (TransformerEncoderLayer)                                      \n",
      "                                                                 \n",
      " transformer_encoder_layer_9  multiple                 198528    \n",
      "  (TransformerEncoderLayer)                                      \n",
      "                                                                 \n",
      " transformer_encoder_layer_1  multiple                 198528    \n",
      " 0 (TransformerEncoderLayer)                                     \n",
      "                                                                 \n",
      " transformer_encoder_layer_1  multiple                 198528    \n",
      " 1 (TransformerEncoderLayer)                                     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            multiple                  16512     \n",
      "                                                                 \n",
      " dense_25 (Dense)            multiple                  5270553   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,931,993\n",
      "Trainable params: 12,931,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BertModel(\n",
    "    num_layers=config.num_layers,\n",
    "    num_heads=config.num_heads,\n",
    "    d_model=config.d_model,\n",
    "    dropout=config.dropout,\n",
    "    layer_norm_eps=config.layer_norm_eps,\n",
    "    activation=config.activation,\n",
    "    vocab_size=config.vocab_size,\n",
    "    max_seq_len=config.max_seq_len,\n",
    ")\n",
    "model.build((config.batch_size, config.max_seq_len))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874bb6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trainer = BertTrainer(model)\n",
    "bert_trainer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/2142 [..............................] - ETA: 155:03:17 - loss: 9.2354 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "bert_trainer.fit(movies_ds, batch_size=config.batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0524a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0bbdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391ba4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1635923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = CustomFit(model)\n",
    "training.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fit(movies_ds, batch_size=64, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da986f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.evaluate(movies_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b554001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce809d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f840831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ee8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23324118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CustomFit)\n",
    "print(isinstance(self, CustomFit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38355f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "training.compile(optimizer=optimizer)\n",
    "training.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(movies_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeError: super(type, obj): obj must be an instance or subtype of type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f54b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55690b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert4rec_model(config):\n",
    "    inputs = tf.keras.layers.Input((config.max_seq_len,), dtype=tf.int64)\n",
    "    bert4rec_model = Bert(\n",
    "        num_layers=12,\n",
    "        num_heads=12,\n",
    "        d_model= 128,\n",
    "        dropout= 0.1,\n",
    "        layer_norm_eps= 1e-12,\n",
    "        activation=\"gelu\",\n",
    "        vocab_size=40857,\n",
    "        max_seq_len=512,\n",
    "    )\n",
    "    model = BertModel()(inputs, bert4rec_model(inputs), name=\"masked_bert_model\")\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=config.LR)\n",
    "    model.compile(optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_masked_model = get_bert4rec_model(config)\n",
    "bert_masked_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66744942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4c026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_masked_model.fit(mlm_ds, epochs=5, callbacks=[generator_callback])\n",
    "bert_masked_model.save(\"bert_mlm_imdb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8c36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f09d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf765e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39538e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example data\n",
    "data = {\n",
    "    'Age': 29,\n",
    "    'Movie': ['The Shawshank Redemption', 'Fight Club'],\n",
    "    'Movie Ratings': [9.0, 9.7],\n",
    "    'Suggestion': 'Inception',\n",
    "    'Suggestion Purchased': 1.0,\n",
    "    'Purchase Price': 9.99\n",
    "}\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Example\n",
    "example = tf.train.Example(features=tf.train.Features(feature={\n",
    "    'Age': tf.train.Feature(\n",
    "        int64_list=tf.train.Int64List(value=[data['Age']])),\n",
    "    'Movie': tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(\n",
    "            value=[m.encode('utf-8') for m in data['Movie']])),\n",
    "    'Movie Ratings': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=data['Movie Ratings'])),\n",
    "    'Suggestion': tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(\n",
    "            value=[data['Suggestion'].encode('utf-8')])),\n",
    "    'Suggestion Purchased': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(\n",
    "            value=[data['Suggestion Purchased']])),\n",
    "    'Purchase Price': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=[data['Purchase Price']]))\n",
    "}))\n",
    "\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write TFrecord file\n",
    "with tf.io.TFRecordWriter('customer_1.tfrecord') as writer:\n",
    "    writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805cca4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ddffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dab90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684aeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c330dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a5e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TFRecord file\n",
    "\n",
    "dataset =  tf.data.TFRecordDataset(['customer_1.tfrecord'])\n",
    "\n",
    "# _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "# Define features\n",
    "read_features = {\n",
    "    'Age': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    'Movie': tf.io.VarLenFeature(dtype=tf.string),\n",
    "    'Movie Ratings': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "    'Suggestion': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'Suggestion Purchased': tf.io.FixedLenFeature([], dtype=tf.float32),\n",
    "    'Purchase Price': tf.io.FixedLenFeature([], dtype=tf.float32)\n",
    "}\n",
    "\n",
    "# Extract features from serialized data\n",
    "read_data = tf.io.parse_single_example(dataset, read_features)\n",
    "\n",
    "# Many tf.train functions use tf.train.QueueRunner,\n",
    "# so we need to start it before we read\n",
    "tf.train.start_queue_runners(sess)\n",
    "\n",
    "# Print features\n",
    "for name, tensor in read_data.items():\n",
    "    print('{}: {}'.format(name, tensor.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25eb907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
