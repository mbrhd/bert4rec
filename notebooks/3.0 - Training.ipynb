{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34e9ad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4241120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf284bc4",
   "metadata": {},
   "source": [
    "## Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "766c59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    num_layers:int=12\n",
    "    num_heads:int=32\n",
    "    d_model:int=128\n",
    "    dropout:float=0.1\n",
    "    layer_norm_eps:float=1e-12\n",
    "    activation:str=\"gelu\"\n",
    "    vocab_size:int=40857\n",
    "    max_seq_len:int=256\n",
    "    learning_rate:float=1e-4\n",
    "    batch_size:float=64\n",
    "        \n",
    "config=Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3c03f",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ba216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/processed/test.tfrecords',\n",
       " '../data/processed/training.tfrecords',\n",
       " '../data/processed/vocab.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob.glob('../data/processed/*')\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b461d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 22:59:27.482814: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.TFRecordDataset(filenames[1])\n",
    "test_data = tf.data.TFRecordDataset(filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c764c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_tf_records(element):\n",
    "    # Parse the input `tf.train.Example` proto using the dictionary schema.\n",
    "    schema = {\n",
    "        \"info\": tf.io.FixedLenFeature([1], tf.int64),  # [user]\n",
    "        \"x_masked_tokens\": tf.io.FixedLenFeature([256], tf.int64),\n",
    "        \"y_tokens\": tf.io.FixedLenFeature([256], tf.int64),\n",
    "        \"mask_layer\": tf.io.FixedLenFeature([256], tf.int64),\n",
    "    }\n",
    "    content = tf.io.parse_single_example(element, schema)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e02f0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_tf_records = train_data.map(_parse_tf_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ac86bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {info: (1,), mask_layer: (256,), x_masked_tokens: (256,), y_tokens: (256,)}, types: {info: tf.int64, mask_layer: tf.int64, x_masked_tokens: tf.int64, y_tokens: tf.int64}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_tf_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "089e5c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "      <th>x_masked_tokens</th>\n",
       "      <th>y_tokens</th>\n",
       "      <th>mask_layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0]</td>\n",
       "      <td>[22, 6, 5, 25, 12, 40857, 26, 14, 34, 21, 1, 4...</td>\n",
       "      <td>[22, 6, 5, 25, 12, 3, 26, 14, 34, 21, 1, 4, 32...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2]</td>\n",
       "      <td>[170, 171, 298, 282, 316, 330, 148, 301, 304, ...</td>\n",
       "      <td>[170, 171, 298, 282, 316, 330, 148, 301, 304, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3]</td>\n",
       "      <td>[165, 40857, 512, 181, 185, 475, 471, 476, 473...</td>\n",
       "      <td>[165, 470, 512, 181, 185, 475, 471, 476, 473, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4]</td>\n",
       "      <td>[40, 40857, 533, 540, 527, 528, 40857, 151, 52...</td>\n",
       "      <td>[40, 0, 533, 540, 527, 528, 530, 151, 529, 517...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[5]</td>\n",
       "      <td>[558, 162, 562, 43, 51, 44, 158, 557, 40857, 5...</td>\n",
       "      <td>[558, 162, 562, 43, 51, 44, 158, 557, 58, 561,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  info                                    x_masked_tokens  \\\n",
       "0  [0]  [22, 6, 5, 25, 12, 40857, 26, 14, 34, 21, 1, 4...   \n",
       "1  [2]  [170, 171, 298, 282, 316, 330, 148, 301, 304, ...   \n",
       "2  [3]  [165, 40857, 512, 181, 185, 475, 471, 476, 473...   \n",
       "3  [4]  [40, 40857, 533, 540, 527, 528, 40857, 151, 52...   \n",
       "4  [5]  [558, 162, 562, 43, 51, 44, 158, 557, 40857, 5...   \n",
       "\n",
       "                                            y_tokens  \\\n",
       "0  [22, 6, 5, 25, 12, 3, 26, 14, 34, 21, 1, 4, 32...   \n",
       "1  [170, 171, 298, 282, 316, 330, 148, 301, 304, ...   \n",
       "2  [165, 470, 512, 181, 185, 475, 471, 476, 473, ...   \n",
       "3  [40, 0, 533, 540, 527, 528, 530, 151, 529, 517...   \n",
       "4  [558, 162, 562, 43, 51, 44, 158, 557, 58, 561,...   \n",
       "\n",
       "                                          mask_layer  \n",
       "0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
       "3  [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    parsed_tf_records.as_numpy_iterator(),\n",
    "    columns=['info', 'x_masked_tokens', 'y_tokens', 'mask_layer']\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ea32765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f6bc374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (np.vstack(df.x_masked_tokens.to_numpy()), \n",
    "    np.vstack(df.y_tokens.to_numpy()), \n",
    "    np.vstack(df.mask_layer.to_numpy()))\n",
    ")\n",
    "movies_ds = movies_ds.shuffle(1000).batch(config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc2b856",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "24114d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert4rec.bert import BertModel\n",
    "from bert4rec.trainer import BertTrainer\n",
    "# %autoreload 2\n",
    "# from bert4rec.trainer import BertTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1181ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert_model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " positional_embedding_37 (Po  multiple                 5262464   \n",
      " sitionalEmbedding)                                              \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 33 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 34 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 35 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 36 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 37 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 38 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 39 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 40 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 41 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 42 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 43 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " transformer_encoder_layer_4  multiple                 198528    \n",
      " 44 (TransformerEncoderLayer                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_480 (Dropout)       multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_960 (Dense)           multiple                  16512     \n",
      "                                                                 \n",
      " dense_961 (Dense)           multiple                  5270553   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,931,865\n",
      "Trainable params: 12,931,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = BertModel(\n",
    "    num_layers=config.num_layers,\n",
    "    num_heads=config.num_heads,\n",
    "    d_model=config.d_model,\n",
    "    dropout=config.dropout,\n",
    "    layer_norm_eps=config.layer_norm_eps,\n",
    "    activation=config.activation,\n",
    "    vocab_size=config.vocab_size,\n",
    "    max_seq_len=config.max_seq_len,\n",
    ")\n",
    "model.build((config.batch_size, config.max_seq_len))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "998ef250",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trainer = BertTrainer(model)\n",
    "bert_trainer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3e6b40c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "(None, 256, 128)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/mbrahimi/dev_perso/bert4rec_attraqt/bert4rec_project/bert4rec/trainer.py\", line 98, in train_step\n        predictions = self.model(x_masked_tokens, training=True)\n    File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"bert_model_14\" (type BertModel).\n    \n    in user code:\n    \n        File \"/Users/mbrahimi/dev_perso/bert4rec_attraqt/bert4rec_project/bert4rec/bert.py\", line 70, in call  *\n            x = self.enc_layers[i](x)\n        File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer \"transformer_encoder_layer_168\" (type TransformerEncoderLayer).\n        \n        in user code:\n        \n            File \"/Users/mbrahimi/dev_perso/bert4rec_attraqt/bert4rec_project/bert4rec/transformer.py\", line 67, in call  *\n                self_attention_output = self.self_attention(\n            File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            ValueError: Exception encountered when calling layer \"query\" (type EinsumDense).\n            \n            Shape must be rank 4 but is rank 3\n            \t for 0th input and equation: abcd,def->abcef for '{{node bert_model_14/transformer_encoder_layer_168/multi_head_attention_168/query/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abcd,def->abcef\"](bert_model_14/positional_embedding_14/add, bert_model_14/transformer_encoder_layer_168/multi_head_attention_168/query/einsum/Einsum/ReadVariableOp)' with input shapes: [?,256,128], [128,12,10].\n            \n            Call arguments received:\n              • inputs=tf.Tensor(shape=(None, 256, 128), dtype=float32)\n        \n        \n        Call arguments received:\n          • x=tf.Tensor(shape=(None, 256, 128), dtype=float32)\n          • attention_mask=None\n          • training=True\n    \n    \n    Call arguments received:\n      • x=tf.Tensor(shape=(None, 256), dtype=int64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovies_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1130\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/mbrahimi/dev_perso/bert4rec_attraqt/bert4rec_project/bert4rec/trainer.py\", line 98, in train_step\n        predictions = self.model(x_masked_tokens, training=True)\n    File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"bert_model_14\" (type BertModel).\n    \n    in user code:\n    \n        File \"/Users/mbrahimi/dev_perso/bert4rec_attraqt/bert4rec_project/bert4rec/bert.py\", line 70, in call  *\n            x = self.enc_layers[i](x)\n        File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer \"transformer_encoder_layer_168\" (type TransformerEncoderLayer).\n        \n        in user code:\n        \n            File \"/Users/mbrahimi/dev_perso/bert4rec_attraqt/bert4rec_project/bert4rec/transformer.py\", line 67, in call  *\n                self_attention_output = self.self_attention(\n            File \"/opt/anaconda3/envs/bert4rec_project/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n        \n            ValueError: Exception encountered when calling layer \"query\" (type EinsumDense).\n            \n            Shape must be rank 4 but is rank 3\n            \t for 0th input and equation: abcd,def->abcef for '{{node bert_model_14/transformer_encoder_layer_168/multi_head_attention_168/query/einsum/Einsum}} = Einsum[N=2, T=DT_FLOAT, equation=\"abcd,def->abcef\"](bert_model_14/positional_embedding_14/add, bert_model_14/transformer_encoder_layer_168/multi_head_attention_168/query/einsum/Einsum/ReadVariableOp)' with input shapes: [?,256,128], [128,12,10].\n            \n            Call arguments received:\n              • inputs=tf.Tensor(shape=(None, 256, 128), dtype=float32)\n        \n        \n        Call arguments received:\n          • x=tf.Tensor(shape=(None, 256, 128), dtype=float32)\n          • attention_mask=None\n          • training=True\n    \n    \n    Call arguments received:\n      • x=tf.Tensor(shape=(None, 256), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "training.fit(movies_ds, batch_size=config.batch_size, epochs=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = CustomFit(model)\n",
    "training.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b0fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.fit(movies_ds, batch_size=64, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150bacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.evaluate(movies_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72795d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b160019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f58f960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d2d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59566f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CustomFit)\n",
    "print(isinstance(self, CustomFit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae8cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f5148",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "training.compile(optimizer=optimizer)\n",
    "training.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(movies_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628af38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TypeError: super(type, obj): obj must be an instance or subtype of type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f54b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55690b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert4rec_model(config):\n",
    "    inputs = tf.keras.layers.Input((config.max_seq_len,), dtype=tf.int64)\n",
    "    bert4rec_model = Bert(\n",
    "        num_layers=12,\n",
    "        num_heads=12,\n",
    "        d_model= 128,\n",
    "        dropout= 0.1,\n",
    "        layer_norm_eps= 1e-12,\n",
    "        activation=\"gelu\",\n",
    "        vocab_size=40857,\n",
    "        max_seq_len=512,\n",
    "    )\n",
    "    model = BertModel()(inputs, bert4rec_model(inputs), name=\"masked_bert_model\")\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=config.LR)\n",
    "    model.compile(optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_masked_model = get_bert4rec_model(config)\n",
    "bert_masked_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66744942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4c026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_masked_model.fit(mlm_ds, epochs=5, callbacks=[generator_callback])\n",
    "bert_masked_model.save(\"bert_mlm_imdb.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8c36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f09d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf765e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39538e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example data\n",
    "data = {\n",
    "    'Age': 29,\n",
    "    'Movie': ['The Shawshank Redemption', 'Fight Club'],\n",
    "    'Movie Ratings': [9.0, 9.7],\n",
    "    'Suggestion': 'Inception',\n",
    "    'Suggestion Purchased': 1.0,\n",
    "    'Purchase Price': 9.99\n",
    "}\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c9433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Example\n",
    "example = tf.train.Example(features=tf.train.Features(feature={\n",
    "    'Age': tf.train.Feature(\n",
    "        int64_list=tf.train.Int64List(value=[data['Age']])),\n",
    "    'Movie': tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(\n",
    "            value=[m.encode('utf-8') for m in data['Movie']])),\n",
    "    'Movie Ratings': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=data['Movie Ratings'])),\n",
    "    'Suggestion': tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(\n",
    "            value=[data['Suggestion'].encode('utf-8')])),\n",
    "    'Suggestion Purchased': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(\n",
    "            value=[data['Suggestion Purchased']])),\n",
    "    'Purchase Price': tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=[data['Purchase Price']]))\n",
    "}))\n",
    "\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf00ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write TFrecord file\n",
    "with tf.io.TFRecordWriter('customer_1.tfrecord') as writer:\n",
    "    writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805cca4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ddffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dab90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684aeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c330dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a5e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TFRecord file\n",
    "\n",
    "dataset =  tf.data.TFRecordDataset(['customer_1.tfrecord'])\n",
    "\n",
    "# _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "# Define features\n",
    "read_features = {\n",
    "    'Age': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "    'Movie': tf.io.VarLenFeature(dtype=tf.string),\n",
    "    'Movie Ratings': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "    'Suggestion': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'Suggestion Purchased': tf.io.FixedLenFeature([], dtype=tf.float32),\n",
    "    'Purchase Price': tf.io.FixedLenFeature([], dtype=tf.float32)\n",
    "}\n",
    "\n",
    "# Extract features from serialized data\n",
    "read_data = tf.io.parse_single_example(dataset, read_features)\n",
    "\n",
    "# Many tf.train functions use tf.train.QueueRunner,\n",
    "# so we need to start it before we read\n",
    "tf.train.start_queue_runners(sess)\n",
    "\n",
    "# Print features\n",
    "for name, tensor in read_data.items():\n",
    "    print('{}: {}'.format(name, tensor.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25eb907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
